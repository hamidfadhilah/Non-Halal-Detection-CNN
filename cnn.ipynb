{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COEGIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data.\n",
      "Data has been loaded.\n",
      "x_train shape: (6188, 20, 20, 1)\n",
      "6188 train samples\n",
      "1547 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COEGIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 36\n",
    "epochs = 50\n",
    "img_rows, img_cols = 20, 20\n",
    "\n",
    "print('Start loading data.')\n",
    "files, labels = helpers.load_chars74k_data()\n",
    "X, y = helpers.create_dataset(files, labels)\n",
    "print('Data has been loaded.')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=2, train_size=0.8)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model.\n",
      "Train on 6188 samples, validate on 1547 samples\n",
      "Epoch 1/50\n",
      "6188/6188 [==============================] - 16s 3ms/step - loss: 14.9606 - acc: 0.0642 - val_loss: 14.1367 - val_acc: 0.0950\n",
      "Epoch 2/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 5.5801 - acc: 0.1534 - val_loss: 2.3124 - val_acc: 0.4066\n",
      "Epoch 3/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 2.2398 - acc: 0.4156 - val_loss: 1.4976 - val_acc: 0.6005\n",
      "Epoch 4/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 1.6201 - acc: 0.5601 - val_loss: 1.1484 - val_acc: 0.6904\n",
      "Epoch 5/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 1.3311 - acc: 0.6336 - val_loss: 0.9792 - val_acc: 0.7369\n",
      "Epoch 6/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 1.1397 - acc: 0.6868 - val_loss: 0.8368 - val_acc: 0.7699\n",
      "Epoch 7/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 0.9666 - acc: 0.7293 - val_loss: 0.8058 - val_acc: 0.7828\n",
      "Epoch 8/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.8535 - acc: 0.7553 - val_loss: 0.7271 - val_acc: 0.7964\n",
      "Epoch 9/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.7631 - acc: 0.7817 - val_loss: 0.6998 - val_acc: 0.8016\n",
      "Epoch 10/50\n",
      "6188/6188 [==============================] - 21s 3ms/step - loss: 0.6907 - acc: 0.7999 - val_loss: 0.6663 - val_acc: 0.8151\n",
      "Epoch 11/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.6282 - acc: 0.8227 - val_loss: 0.6671 - val_acc: 0.8216\n",
      "Epoch 12/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.5809 - acc: 0.8287 - val_loss: 0.6836 - val_acc: 0.8158\n",
      "Epoch 13/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.5273 - acc: 0.8428 - val_loss: 0.6000 - val_acc: 0.8397\n",
      "Epoch 14/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.4867 - acc: 0.8510 - val_loss: 0.6209 - val_acc: 0.8416\n",
      "Epoch 15/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.4529 - acc: 0.8652 - val_loss: 0.6393 - val_acc: 0.8197\n",
      "Epoch 16/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 0.4074 - acc: 0.8749 - val_loss: 0.6034 - val_acc: 0.8462\n",
      "Epoch 17/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.3865 - acc: 0.8817 - val_loss: 0.5996 - val_acc: 0.8397\n",
      "Epoch 18/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.3658 - acc: 0.8935 - val_loss: 0.5979 - val_acc: 0.8468\n",
      "Epoch 19/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.3292 - acc: 0.9017 - val_loss: 0.6334 - val_acc: 0.8436\n",
      "Epoch 20/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.3325 - acc: 0.8954 - val_loss: 0.6396 - val_acc: 0.8442\n",
      "Epoch 21/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.3150 - acc: 0.9040 - val_loss: 0.6167 - val_acc: 0.8410\n",
      "Epoch 22/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2897 - acc: 0.9079 - val_loss: 0.6122 - val_acc: 0.8494\n",
      "Epoch 23/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2952 - acc: 0.9103 - val_loss: 0.6099 - val_acc: 0.8423\n",
      "Epoch 24/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2767 - acc: 0.9156 - val_loss: 0.6454 - val_acc: 0.8436\n",
      "Epoch 25/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 0.2668 - acc: 0.9176 - val_loss: 0.5877 - val_acc: 0.8520\n",
      "Epoch 26/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2516 - acc: 0.9239 - val_loss: 0.6617 - val_acc: 0.8455\n",
      "Epoch 27/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2266 - acc: 0.9303 - val_loss: 0.6751 - val_acc: 0.8481\n",
      "Epoch 28/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2370 - acc: 0.9266 - val_loss: 0.6676 - val_acc: 0.8474\n",
      "Epoch 29/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 0.2255 - acc: 0.9287 - val_loss: 0.6699 - val_acc: 0.8449\n",
      "Epoch 30/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.2108 - acc: 0.9305 - val_loss: 0.6803 - val_acc: 0.8500\n",
      "Epoch 31/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1989 - acc: 0.9350 - val_loss: 0.6543 - val_acc: 0.8507\n",
      "Epoch 32/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.2199 - acc: 0.9336 - val_loss: 0.6983 - val_acc: 0.8604\n",
      "Epoch 33/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.2069 - acc: 0.9360 - val_loss: 0.6163 - val_acc: 0.8597\n",
      "Epoch 34/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.1943 - acc: 0.9410 - val_loss: 0.6767 - val_acc: 0.8533\n",
      "Epoch 35/50\n",
      "6188/6188 [==============================] - 21s 3ms/step - loss: 0.1942 - acc: 0.9405 - val_loss: 0.7410 - val_acc: 0.8494\n",
      "Epoch 36/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1965 - acc: 0.9402 - val_loss: 0.7157 - val_acc: 0.8552\n",
      "Epoch 37/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1839 - acc: 0.9444 - val_loss: 0.6754 - val_acc: 0.8546\n",
      "Epoch 38/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1613 - acc: 0.9486 - val_loss: 0.6365 - val_acc: 0.8636\n",
      "Epoch 39/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.1690 - acc: 0.9472 - val_loss: 0.6856 - val_acc: 0.8571\n",
      "Epoch 40/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 0.1597 - acc: 0.9493 - val_loss: 0.7350 - val_acc: 0.8565\n",
      "Epoch 41/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1509 - acc: 0.9543 - val_loss: 0.7370 - val_acc: 0.8617\n",
      "Epoch 42/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 0.1690 - acc: 0.9484 - val_loss: 0.7436 - val_acc: 0.8623\n",
      "Epoch 43/50\n",
      "6188/6188 [==============================] - 18s 3ms/step - loss: 0.1382 - acc: 0.9619 - val_loss: 0.6237 - val_acc: 0.8623\n",
      "Epoch 44/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1556 - acc: 0.9535 - val_loss: 0.7621 - val_acc: 0.8546\n",
      "Epoch 45/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1533 - acc: 0.9539 - val_loss: 0.6643 - val_acc: 0.8720\n",
      "Epoch 46/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1516 - acc: 0.9549 - val_loss: 0.6869 - val_acc: 0.8643\n",
      "Epoch 47/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1512 - acc: 0.9527 - val_loss: 0.6728 - val_acc: 0.8681\n",
      "Epoch 48/50\n",
      "6188/6188 [==============================] - 17s 3ms/step - loss: 0.1323 - acc: 0.9598 - val_loss: 0.7296 - val_acc: 0.8578\n",
      "Epoch 49/50\n",
      "6188/6188 [==============================] - 19s 3ms/step - loss: 0.1477 - acc: 0.9562 - val_loss: 0.6939 - val_acc: 0.8623\n",
      "Epoch 50/50\n",
      "6188/6188 [==============================] - 20s 3ms/step - loss: 0.1378 - acc: 0.9552 - val_loss: 0.6983 - val_acc: 0.8610\n",
      "Model has been trained.\n",
      "Test loss: 0.6983238151170549\n",
      "Test accuracy: 0.8610213315710378\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# train_generator, validation_generator = helpers.create_datagenerator(x_train, x_test, y_train, y_test)\n",
    "\n",
    "# Convolutional network will be build with Keras.\n",
    "print('Start training the model.')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(train_generator,\n",
    "#                     steps_per_epoch=10000 // batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=validation_generator,\n",
    "#                     validation_steps=6000 // batch_size)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Calculate loss and accuracy.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Model has been trained.')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from out/chars74k_convnet.chkp\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n",
      "graph saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "MODEL_NAME = 'chars74k_convnet'\n",
    "saver = tf.train.Saver()\n",
    "input_node_names = [\"conv2d_1_input\"]\n",
    "output_node_name = \"dense_2/Softmax\"\n",
    "\n",
    "\n",
    "tf.train.write_graph(K.get_session().graph_def, 'out', \\\n",
    "                     MODEL_NAME + '_graph.pbtxt', as_text=True)\n",
    "\n",
    "saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\n",
    "\n",
    "freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "print(\"graph saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.python.framework import graph_util\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import keras.models\n",
    "from keras.models import model_from_json\n",
    "from scipy.misc import imread, imresize,imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import helpers\n",
    "\n",
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#load woeights into new model\n",
    "\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "model = loaded_model.load_weights(\"model.h5\")\n",
    "sess = K.get_session()\n",
    "\n",
    "output_node_name = \"dense_2/Softmax\" # Name of your output node\n",
    "\n",
    "with sess as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    graph_def = sess.graph.as_graph_def()\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "                                                                 sess,\n",
    "                                                                 sess.graph.as_graph_def(),\n",
    "                                                                 output_node_name.split(\",\"))\n",
    "    tf.train.write_graph(output_graph_def,\n",
    "                         logdir=\"my_dir\",\n",
    "                         name=\"my_model.pb\",\n",
    "                         as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-20c2f477e35d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m211\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())  \n",
    "\n",
    "plt.figure(1)  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    " \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
